{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ipyparallel\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "c = ipyparallel.Client()\n",
    "view = c.load_balanced_view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Loading, indexing, and grouping data...')\n",
    "#read in all coded data\n",
    "answers = pd.read_csv('data/merged_relevant.tsv', sep='\\t')\n",
    "#set indices\n",
    "answers = answers.set_index(['uni', 'Participant', 'Start'])\n",
    "#group codes at the person level\n",
    "people = answers.groupby(level=['uni', 'Participant']).any()\n",
    "\n",
    "print(answers.shape)\n",
    "print(people.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def list_people_data(df):\n",
    "    '''Generates a list of input to be mapped to parallel_jaccard().'''\n",
    "    #add a unique ID column\n",
    "    n = len(df)\n",
    "    idx = range(0, n)\n",
    "    df['uid'] = idx\n",
    "    id_map = df[['uid']]\n",
    "    df = df.set_index(['uid'])\n",
    "    #transpose data frame for easier indexing\n",
    "    data = df.transpose()\n",
    "    result = []\n",
    "    #create a list of jobs where each job is an element and a\n",
    "    #set of other elements to compare it with.\n",
    "    for i in range(0, n):\n",
    "        dic = {'i':i, 'dat':data.iloc[:,0:i+1]}\n",
    "        result.append(dic)\n",
    "            \n",
    "    return (id_map, result)\n",
    "\n",
    "def parallel_jaccard(dic):\n",
    "    '''Map function to be used in parallel computation of \n",
    "    all v all jaccard similarity. Individual pairwise comparisons\n",
    "    proved to be too small of jobs for decent parallel computation.\n",
    "    Thus, each job compares one element i to all other elements \n",
    "    in range(0, i).\n",
    "    For space efficiency, a dictionary of non-zero scores is returned\n",
    "    instead of an adjacency matrix.\n",
    "    '''\n",
    "    #what column to use as our reference\n",
    "    i = dic['i']\n",
    "    #our data\n",
    "    data = dic['dat']\n",
    "    a = data[i]\n",
    "    #the number of codes we're comparing across columns\n",
    "    codes = data.shape[0]\n",
    "\n",
    "    output = {}\n",
    "    \n",
    "    #loop over all the columns we need to compare\n",
    "    for k in range(0, i):\n",
    "        #temp variables\n",
    "        union = 0.0\n",
    "        intersection = 0.0\n",
    "        b = data[k]\n",
    "        #loop over the codes to compare in these cols\n",
    "        for j in range(0, codes):\n",
    "            #if at least one has a code\n",
    "            if a[j] | b[j]:\n",
    "                intersection = intersection + 1\n",
    "                #if both have the code\n",
    "                if a[j] & b[j]:\n",
    "                    union = union + 1\n",
    "        #only save scores > 0\n",
    "        if (intersection > 0) & (union > 0):\n",
    "            output[k] = (union / intersection) \n",
    "            \n",
    "    return {'i':i, 'Jaccard':output}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(id_map, result) = list_people_data(people)\n",
    "#result[2]['dat']\n",
    "tmp = id_map.reset_index()\n",
    "tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = view.map_async(parallel_jaccard, result)\n",
    "output.wait_interactive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Stitching results together...')\n",
    "tmp = []\n",
    "for o in output:\n",
    "    tmp.append(pd.DataFrame.from_dict(o))\n",
    "tmp = pd.concat(tmp)\n",
    "\n",
    "#now make things pretty for saving\n",
    "tmp['j'] = tmp.index\n",
    "#tmp = tmp[['i','j','Jaccard']]\n",
    "tmp.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r.to_csv('data/people_jaccard.tsv', sep='\\t')\n",
    "m.to_csv('data/people_jaccard_ids.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_graph_person(g, save_to='test.png'):\n",
    "    '''Display our network. Customize to best suit your own needs.'''\n",
    "    plt.figure(figsize=(25,25))\n",
    "    \n",
    "    #layout nodes and their labels\n",
    "    pos=nx.spring_layout(g)\n",
    "    nx.draw_networkx_nodes(g, pos)\n",
    "\n",
    "    #divide edges into groups based on weight\n",
    "    #i.e. statistical significance of cooccurance\n",
    "    e999 =[(u, v) for (u, v, d) in g.edges(data=True) if \n",
    "           (d['weight'] >= 0.9)]\n",
    "    e990 =[(u, v) for (u, v, d) in g.edges(data=True) if \n",
    "           (d['weight'] < 0.9) & (d['weight'] >= 0.75)]\n",
    "    e950 =[(u, v) for (u, v, d) in g.edges(data=True) if \n",
    "           (d['weight'] < 0.75) & (d['weight'] >= 0.5)]\n",
    "    e841 =[(u, v) for (u, v, d) in g.edges(data=True) if \n",
    "           (d['weight'] < 0.5) & (d['weight'] >= 0.25)]\n",
    "    \n",
    "    #draw edges in each group\n",
    "    nx.draw_networkx_edges(g, pos, edgelist=e999, width=6, alpha=0.5)\n",
    "    nx.draw_networkx_edges(g, pos, edgelist=e990, width=2)#, alpha=0.5)\n",
    "    #nx.draw_networkx_edges(g, pos, edgelist=e950, width=2, alpha=0.5,\n",
    "    #                       edge_color='b')\n",
    "    #nx.draw_networkx_edges(g, pos, edgelist=e841, width=2, alpha=0.5,\n",
    "    #                       edge_color='b', style='dashed')\n",
    "\n",
    "    #axes look silly here\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_net(data, min_weight=0, isolates=False, directed=False):\n",
    "    '''Create a networkx network from our dataframe of edge weights\n",
    "    Input:\n",
    "        data: a symmetric pandas data frame of edge weights\n",
    "        min_weight: ignore weights at or below this number\n",
    "        isolates: boolean, do we include nodes without edges?\n",
    "    '''\n",
    "    nodes = data.columns.values\n",
    "    \n",
    "    if directed:\n",
    "        g = nx.DiGraph()\n",
    "    else:\n",
    "        g = nx.Graph()\n",
    "        #this case will have us add all edges twice, but nx doesn't mind\n",
    "        #and a graph of codes is too small for the performance to matter\n",
    "    \n",
    "    #if we want to include even nodes without edges\n",
    "    if isolates:\n",
    "        g.add_nodes_from(nodes)\n",
    "            \n",
    "    #iterate over data matrix\n",
    "    for r in nodes: #rows\n",
    "        for c in nodes: #columns\n",
    "            if r == c:\n",
    "                #skip self-loops\n",
    "                continue\n",
    "            #if this edge has enough weight, add it\n",
    "            if data.loc[r, c] > min_weight: \n",
    "                g.add_edge(r, c, weight = data.loc[r, c])                      \n",
    "\n",
    "    return g\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = make_net(tmp, min_weight=.75)#, isolates=True)\n",
    "show_graph_person(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(m2, r2) = all_v_all_jaccard_sim(answers)\n",
    "r2.to_csv('data/ans_jaccard.tsv', sep='\\t')\n",
    "m2.to_csv('data/ans_jaccard_ids.tsv', sep='\\t')\n",
    "r2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g2 = make_net(r2, min_weight=.75)\n",
    "show_graph_person(g2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(((9346 ** 2) - 9346 ) / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp = pd.read_csv('data/answers_jaccard.tsv', sep='\\t')\n",
    "tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
